{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import os\n",
    "from os.path import isfile, join, isdir, exists\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from speechbrain.pretrained import SepformerSeparation as separator\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "# torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the data\n",
    "\n",
    "directory = \"standardized_split_audio\"\n",
    "save_directory = \"audio_split_sb\"\n",
    "if not exists(save_directory):\n",
    "   os.mkdir(\"./\"+save_directory)\n",
    "    \n",
    "dirnames = [f for f in os.listdir(directory) if isdir(join(directory, f))]\n",
    "\n",
    "for d in dirnames:\n",
    "    if not exists(join(save_directory, d)):\n",
    "        os.mkdir(join(save_directory, d))\n",
    "\n",
    "tbc = [2, 12, 16, 17, 27, 29, 36, 53, 62, 76, 83, 93, 95, 110, 111, 112, 122, 38, 71, 84, 85, 100, 117]\n",
    "\n",
    "fnames = []\n",
    "for dirs in dirnames:\n",
    "    for f in os.listdir(join(directory, dirs)):\n",
    "        if int(f[:-5]) in tbc:\n",
    "            fnames.append(join(dirs, f))\n",
    "\n",
    "for fname in fnames:\n",
    "    f = fname\n",
    "    print(\"starting \", fname)\n",
    "    \n",
    "    fname = join(directory, fname)\n",
    "    if(fname[-3:] != 'wav'):\n",
    "        continue\n",
    "    \n",
    "    # model = BaseModel.from_pretrained('JorisCos/ConvTasNet_Libri2Mix_sepnoisy_16k', sample_rate=44100)\n",
    "    model = separator.from_hparams(source=\"speechbrain/sepformer-whamr\", savedir='pretrained_models/sepformer-whamr', run_opts={\"device\": device})\n",
    "\n",
    "    est_sources = model.separate_file(fname)\n",
    "    est_sources = est_sources.cpu()\n",
    "    transform = torchaudio.transforms.Resample(44100, 8000)\n",
    "    est_sources = transform(est_sources)\n",
    "    torchaudio.save(join(save_directory, f[:-4] + \"_0.wav\"), est_sources[:, :, 0], 8000)\n",
    "    torchaudio.save(join(save_directory, f[:-4] + \"_1.wav\"), est_sources[:, :, 1], 8000)\n",
    "    \n",
    "    # model.separate(fname, save_dir=save_directory, force_overwrite=True)\n",
    "    print(\"Done with \", f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
